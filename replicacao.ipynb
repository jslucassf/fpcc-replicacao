{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando um Classificador de Notícias Falsas no Corpus Fake.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_O trabalho aqui realizado é uma replicação dos experimentos descritos em [1]._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_fake = utils.import_metadata(\"fake\")\n",
    "noticias_fake[\"true\"] = 0\n",
    "noticias_true = utils.import_metadata(\"true\")\n",
    "noticias_true[\"true\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias = noticias_fake.append(noticias_true)\n",
    "noticias = noticias.drop([\"author\", \"link\", \"category\", \"date_of_publication\", \"number_of_tokens\", \"words_without_punct\", \"number_of_types\",\n",
    "               \"number_of_links\", \"upper_case_words\", \"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_fake_corpo = utils.import_texto(\"fake\")\n",
    "noticias_true_corpo = utils.import_texto(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_fake_corpo = utils.normaliza_texto(noticias_fake_corpo)\n",
    "noticias_true_corpo = utils.normaliza_texto(noticias_true_corpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for noticia in sorted(noticias_fake_corpo.keys()):\n",
    "    corpus.append(\" \".join(noticias_fake_corpo[noticia]))\n",
    "for nocicia in sorted(noticias_true_corpo.keys()):\n",
    "    corpus.append(\" \".join(noticias_true_corpo[noticia]))\n",
    "    \n",
    "X = vectorizer.fit_transform(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "bow = bow.iloc[:,520:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([noticias, bow], axis=1, join_axes=[noticias.index])\n",
    "result[\"non_immediacy\"] = noticias.sing_first_sec_personal_pronouns + noticias.plural_first_personal_pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberando memória\n",
    "del noticias_fake, noticias_true, noticias_fake_corpo, noticias_true_corpo, vectorizer, corpus, X, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml\n",
    "\n",
    "# Modelo 1: POS tags\n",
    "metricas_pos_f = ml.train_evaluate(result, features = \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Modelo 2: Bag of Words\n",
    "metricas_bow = ml.train_evaluate(result, features = \"bow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: POS + BoW\n",
    "metricas_pos_bow = ml.train_evaluate(result, features = \"pos+bow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 4: Pausality\n",
    "metricas_pau = ml.train_evaluate(result, features = \"pau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 5: Emotiveness\n",
    "metricas_emo = ml.train_evaluate(result, features = \"emo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 6: Uncertainty\n",
    "metricas_unc = ml.train_evaluate(result, features = \"unc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 7: Non-Immediacy\n",
    "metricas_nim = ml.train_evaluate(result, features = \"nim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 8: Pausality + Emotiveness + Uncertainty + Non-Immediacy\n",
    "metricas_peun = ml.train_evaluate(result, features = \"p+e+u+n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 9: Bag of Words + Emotiveness\n",
    "metricas_bow_emo = ml.train_evaluate(result, features = \"bow+e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 10: Todas as features\n",
    "metricas_all = ml.train_evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      3600\n",
      "           1       0.91      0.85      0.88      3600\n",
      "\n",
      "    accuracy                           0.88      7200\n",
      "   macro avg       0.88      0.88      0.88      7200\n",
      "weighted avg       0.88      0.88      0.88      7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metricas_peun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monteiro, Rafael A., et al. \"Contributions to the Study of Fake News in Portuguese: New Corpus and Automatic Detection Results.\" International Conference on Computational Processing of the Portuguese Language. Springer, Cham, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatorio = open(\"relatorio.txt\", \"a\")\n",
    "relatorio.write(\"POS \" + metricas_pos_f)\n",
    "relatorio.write(\"BoW \" + metricas_bow)\n",
    "relatorio.write(\"POS + BoW \" + metricas_pos_bow)\n",
    "relatorio.write(\"PAU \" + metricas_pau)\n",
    "relatorio.write(\"Emo \" + metricas_emo)\n",
    "relatorio.write(\"Unc \" + metricas_unc)\n",
    "relatorio.write(\"NIM \" + metricas_nim)\n",
    "relatorio.write(\"PEUN \" + metricas_peun)\n",
    "relatorio.write(\"BoW + Emo \" + metricas_bow_emo)\n",
    "relatorio.write(\"Todas \" + metricas_all)\n",
    "relatorio.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
